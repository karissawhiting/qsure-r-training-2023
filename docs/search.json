[
  {
    "objectID": "r-reproducibility.html",
    "href": "r-reproducibility.html",
    "title": "",
    "section": "",
    "text": "R Training 2023\nComputational Reproducibility\nKarissa Whiting\nJune 8th, 2023\n\n\n\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\nAgenda\n\nIntroduction into Reproducibilty\nProject Setup\nCoding Exercise\n\n\n\nWhat is Reproducibility?\n\nA data analysis is reproducible if all the information (data, files, etc.) needed to compute results is available for someone else to re-do your entire analysis and get the same results.\n\nAll data processing steps from raw data to cleaned data are available and documented\nAll analysis decisions made are documented and available in code\nResults don’t depend on your specific computational environment (e.g. no hard coded file paths, seeds set for stochastic computations)\n\n\n\n\nWhy is Reproducibility Important?\n\n\nAllows you to show evidence of your results\nEncourages transparency about decisions made during analysis\nEnables others to check and use/extend your methods and results\nEnables FUTURE YOU to check and use/extend your methods and results\n\n\n“You mostly collaborate with yourself, and me-from-two-months-ago never responds to email”\n\nDr. Mark Holder, Computational Biologist\n\n\n\n\n\nHow Do We Ensure Our Code is Reproducible?\n\n\nHave a clear project structure and defined workflow\nComment and document your code\nUse reproducible reporting practice (e.g. Rmd, quarto, Jupyter notebook, inline text stats)\nAvoid absolute file paths (e.g. ~/Users/Whiting/Projects...)\nVersion control (document changes you make, or use git!)\n\n\n\n\nCoding Exercise\nCase Study: Diabetes Risk Factors\n\n\nCase Study - Modeling Diabetes Risk Factors\n\nResearch Question: Is waist to hip ratio a risk factor for diabetes?\nOutcome: glycosolated hemoglobin level (> 7 is considered diabetic)\n\n\n\nAvailable Variables of interest:\n\ncholesterol level\nstabilized glucose\nlocation of individual\nage\ngender\nheight/weight\nbody frame\nwaist in inches\nhip in inches\n\n\n\nlibrary(faraway)\n?diabetes\n\n\nProject Setup: Anatomy of a Project\n\n\n\n\n\n\n\nkeep raw and processed data separate (raw-data, vs. data)\nfolder for scripts ordered or labelled descriptively\noptionally can have admin for project notes, etc and outputs for final reports and figures\nREADME - text file that introduces and explains a project (usethis::use_readme_md())\nR Project (.Rproj file)  - tells RStudio all your files belong to one project and sets working directory for entire project.\n\n\n\n\n\nProject Setup\n\nCreate a new folder on your computer and name it “your-initials-case-study-2022”\nCreate subfolders within your project folder called: admin, raw-data, scripts, data, outputs\nCreate a new R Project in Rstudio from this folder (File > New Project > Existing Directory)\nGo to https://github.com/karissawhiting/qsure-case-study and click Code > Download ZIP\nCreate a README.md using usethis::use_readme_md()\nDrag contents of raw-data and scripts from qsure-case-study-2022 to your new Project.\n\n\n\nThank You!\n\n\nResources\n\nThese materials will available on Github\nData wrangling cheat sheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\nQuestions? Reach out on teams or via email\nCreate an R help channel on teams- help each other!\n\n\n\nBonus Slides: Why Write a Function?\n\nD.R.Y. - limit copy pasting and potential mistakes\nAutomate common tasks\nYou only need to update code in one place\nIf you are copy pasting code > 3 times, write a function\nGive your function a useful name\n\n\n\nBonus Slides: Function Example\nadd_one <- function(number) {\n  result = number + 1 \n  return(result)\n}\n\nadd_one(7)\n[1] 8\n#add_one(\"hai\")\n\n\nBonus Slides: Function Practice\nWrite a function to calculate BMI given height (inchs) and weight (lbs)\nBMI = (weight * 703) / (height)^2\ncalc_bmi <- function() {\n  ?????????????\n}"
  },
  {
    "objectID": "r-basics.html",
    "href": "r-basics.html",
    "title": "",
    "section": "",
    "text": "QSURE R Training 2023  R Basics\nKarissa Whiting\nJune 7th, 2023\n\n\n\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\nR Workshop Goal\nFill potential gaps in your R knowledge and help you get properly set up to conduct impactful and reproducible research during your time at MSK (and after!)\n\nShort review on basic R vocab\nSkip dplyr basics but include some advanced dplyr/data cleaning\nFocus on project setup\nFocus on coding statistical analyses\nOptional 3rd session on R package making/Github\n\n\n\nTraining Agenda\n\nLesson 1 – 6/7/2023\n\nR Basics (Quick Review)\n\nLesson 2 - 6/8/2023\n\nGuided Example\n\nProject Setup & Reproducibility\nData Cleaning\nAnalyzing/Modeling the Data\nReporting Your Results\n\n\nLesson 3 - TBD\n\nGithub?\nIntro to Package Development?\n\n\n\n\nIntroductions\n\nName, Preferred pronouns\nHave you used R before? If so, how long (< 1 year, 1-3 years, > 3 years)?\nAre you familiar with tidyverse?\nWhat are you working on (you may not know yet!) ?\n\n\n\nR, Rstudio, Open source philosophy\n\nR is an object-oriented open-source programming language used mostly for statistical computing and graphics\nOpen source means the original source code is freely available, and can be distributed and modified. Also, users can contribute to the usefulness by creating packages, which implement specialized functions for all kinds of uses (e.g. statistical methods, graphical capabilities, reporting tools). Added Bonus: vibrant R community!\nRStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting code editor that supports direct code execution, as well as tools for plotting, history, debugging and work space management.\n\n\n\n\n\n\n\n\n\nR Basics: General Things\n\n<- is the assignment operator (= also works)\n\nv1 <- c(1, 2, 3)\nv1\n[1] 1 2 3\n\nThe %>% (pipe) from the magrittr package is a useful way to link functions together to make your code more succinct and easier to read\n\nlibrary(dplyr)\n\nmtcars %>% \n    select(mpg) %>% \n    filter(mpg == max(mpg))\n\n? is your friend if you want to look at documentation! (e.g. type ?mean() in the console)\nR is case sensitive, bE cArEfUl!\n\n\n\nR Basics: Data Structures and Basic Syntax\nR basic data types:\n\nlogical (TRUE)\ninteger (1)\nnumeric (a.k.a. double) (1.2)\ncharacter (\"Purple\")\nfactor (“a”)\ncomplex (nobody ever uses these really)\n\n\n\nR Basics: Beware Data Type Coercion\n\nSince columns of a data.frame must be of the same type, some data may be coerced in unexpected ways when reading in a csv or excel file.\ncharacter is often the default for mixed data types\n\nx <- c(\"apple\", 3)\nstr(x)\nchr [1:2] “apple” “3”\ny <- c(3, 2, \"twenty\") \ny\n[1] “3” “2” “twenty”\n#sum(y)\n\n\nR Basics: Data Structures and Basic Syntax\nR has 5 basic data structures:\n\n\n\nvector\nmatrix\nlist\narray\ndata.frame/tibble\n\n\n\n\n\n\n\nR Basics: Data Structures and Basic Syntax\n\n\n\nvector\n\n\n\nonly 1 data type allowed\n\n# character\nc(\"apple\", \"orange\")\n[1] “apple” “orange”\n# numeric\nc(1:15)\n[1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\n\n\n\nR Basics: Data Structures and Basic Syntax\n\n\n\nvector\nmatrix\n\n\n2d, only 1 data type allowed\n\nletters <- c(\"a\",\"b\",\"c\",\"d\", \"e\", \"f\")\nmatrix(letters, nrow=2, ncol=3)\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"c\"  \"e\" \n[2,] \"b\"  \"d\"  \"f\" \n\n\n\n\n\n\nR Basics: Data Structures and Basic Syntax\n\n\n\nvector\nmatrix\nlist\n\n\n\nany data type allowed\n\n\nmy_list <- list(\"a\", 2, TRUE) \nstr(my_list)\n\nList of 3\n $ : chr \"a\"\n $ : num 2\n $ : logi TRUE\n\n\n\n\n\n\nR Basics: Data Structures and Basic Syntax\n\n\n\nvector\nmatrix\nlist\narray\n\n\n\nn-dimensions, of 1 data type\n\n\n# Create two vectors of different lengths.\nvector1 <- c(5,9,3)\nvector2 <- c(10,11,12,13,14,15)\n\narray(c(vector1,vector2),dim = c(3,3,2))\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    5   10   13\n[2,]    9   11   14\n[3,]    3   12   15\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    5   10   13\n[2,]    9   11   14\n[3,]    3   12   15\n\n\n\n\n\n\nR Basics: Data Structures and Basic Syntax\n\n\n\nvector\nmatrix\nlist\narray\ndata.frame/tibble\n\n\n- any data type is allowed, but each column has to have the same type\n- the most important for data analysts. Most similar to an excel spreadsheet/statistical data file\nhead(iris, 4)\n\n\n\n\n\n\nSepal.Length\n\n\nSepal.Width\n\n\nPetal.Length\n\n\nPetal.Width\n\n\nSpecies\n\n\n\n\n\n\n\n5.1\n\n\n3.5\n\n\n1.4\n\n\n0.2\n\n\nsetosa\n\n\n\n\n4.9\n\n\n3.0\n\n\n1.4\n\n\n0.2\n\n\nsetosa\n\n\n\n\n4.7\n\n\n3.2\n\n\n1.3\n\n\n0.2\n\n\nsetosa\n\n\n\n\n4.6\n\n\n3.1\n\n\n1.5\n\n\n0.2\n\n\nsetosa\n\n\n\n\n\n\n\n\n\n\nExploring Your Data: Identify Data Types\n\ncolnames() - will give you the column names\nncol() and nrow() - will give you the total count of columns and rows respectively\nclass(), str(), attributes() will give you meta-information on the object\nhead(), tail() show the top or bottom rows of your df\nView() will show the whole dataframe\ntable() will summarise variables\n\nstr(iris)\n‘data.frame’: 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 … $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 … $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 … $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 … $ Species : Factor w/ 3 levels “setosa”,“versicolor”,..: 1 1 1 1 1 1 1 1 1 1 …\nnrow(iris)\n[1] 150\n\n\nExploring Your Data: Identify Data Types cont.\ncolnames(iris)\n[1] “Sepal.Length” “Sepal.Width” “Petal.Length” “Petal.Width” “Species”\nclass(iris)\n[1] “data.frame”\nhead(iris[,1:3], 3)\n\n\n\n\n\n\nSepal.Length\n\n\nSepal.Width\n\n\nPetal.Length\n\n\n\n\n\n\n\n5.1\n\n\n3.5\n\n\n1.4\n\n\n\n\n4.9\n\n\n3.0\n\n\n1.4\n\n\n\n\n4.7\n\n\n3.2\n\n\n1.3\n\n\n\n\n\n\ntable(iris$Species)\nsetosa versicolor  virginica \n    50         50         50 \n\n\nIntro to tidyverse\nThe tidyverse package is a collection of R packages designed for data analysis, all of which share a similar design, grammar, and structure.\n\n# load it\nlibrary(tidyverse)\n\n# check out the cute logo\ntidyverse_logo()\n\n⬢ __  _    __   .    ⬡           ⬢  . \n / /_(_)__/ /_ ___  _____ _______ ___ \n/ __/ / _  / // / |/ / -_) __(_-</ -_)\n\\__/_/\\_,_/\\_, /|___/\\__/_/ /___/\\__/ \n     ⬢  . /___/      ⬡      .       ⬢ \n\n\n\n\nIntro to tidyverse\n\nreadr: data import/export\ntibble: easier to work with data frames\ndplyr: data manipulation\ntidyr: data manipulation\nggplot2: graphics and visualization\npurrr: functional programming toolkit, replaces the need for many loops\nstringr: string manipulation\nforcats: re-imagined factor data types\n\nThere are several additional packages which are installed as part of the tidyverse, but are not loaded by default.\n\n\nIntro to tidyverse\nOverall tidyverse helps with code readability and has shortcuts for some common data manipulation tasks\ntidyverse has been developed and significantly improved in the last few years, with a lot of ongoing work being done to further increase usability.\n\n\nThe R Analysis Workflow\n\nSetup Your Project\nClean and Explore Data\n\ntidyverse\n\nAnalyze it\n\nstats\nsurvival, lme4, nlme\nggplot2\n\nReport Your Findings\n\nR Markdown / quarto\ngt / gtsummary\n\nIterate, Share, and Collaborate!\n\ngit/ github\n\n\n\n\nClean and Explore Data\nThe dplyr package is a data manipulation and cleaning package. A few of the key functions (verbs) in dplyr are:\n\nselect()\nmutate()\nfilter()\narrange()\ngroup_by()\nsummarize()\n\nAll take a data frame as input, and return a data frame as output.\nWe will briefly review during case study\n\n\nThe R Analysis Workflow\n\nSetup Your Project\nClean and Explore Data\n\ntidyverse\n\nAnalyze it\n\nstats\nsurvival, lme4, nlme\nggplot2\n\nReport Your Findings\n\nR Markdown / quarto\ngt / gtsummary\n\nIterate, Share, and Collaborate!\n\ngit/ github\n\n\n\n\nModel Statistical analyses\nWe will cover:\n\nlinear model\nlogistic model\nsurvival analyses\n\n\n\nGeneral modeling formula\n\nin general ~ is used to separate your outcome on the left hand side and your predictors on the right hand side\nyour outcome will always be on the left side of the ~\nonly some univariate tests like chisq.test() do not use the ~ notation\ngeneral notation: model(outcome ~ covariates, data)\nthe stats package is already loaded in R which will make it easier to use common statistical tests\n\n\n\nExample of linear model\n\nContinuous outcome\nSpecifying interactions\n\nmtcars$vs  <- as.character(mtcars$vs)\nmtcars$cyl   <- as.character(mtcars$cyl)\nmod1 <- lm(mpg ~ vs * cyl, data = mtcars)\nclass(mod1) # class of lm which is a list\n[1] “lm”\nnames(mod1)\n[1] “coefficients” “residuals” “effects” “rank”\n[5] “fitted.values” “assign” “qr” “df.residual”\n[9] “contrasts” “xlevels” “call” “terms”\n[13] “model”\n\n\nExample cont.\n\nsummary(mod1)\n\n\nCall:\nlm(formula = mpg ~ vs * cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.3300 -1.4437  0.0875  1.5250  7.1700 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   26.000      3.318   7.836    2e-08 ***\nvs1            0.730      3.480   0.210  0.83541    \ncyl6          -5.433      3.831  -1.418  0.16757    \ncyl8         -10.900      3.434  -3.174  0.00374 ** \nvs1:cyl6      -2.172      4.305  -0.504  0.61801    \nvs1:cyl8          NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.318 on 27 degrees of freedom\nMultiple R-squared:  0.7361,    Adjusted R-squared:  0.697 \nF-statistic: 18.82 on 4 and 27 DF,  p-value: 1.696e-07\n\n\n\n\nCheck model diagnositcs\nlibrary(car)\n#model diagnositics\n\n#multi colinearity\n#vifmod <- car::vif(mod1) #will not work with interaction present\nCompute a cutoff point for Cook’s Distance, which is a measure of how influential a data point is in a regression analysis\n#influencers \ncutoff <- 4/((nrow(mtcars)-length(mod1$coefficients)-2)) \nIf the Cook’s Distance of a data point exceeds this cutoff, that data point might be considered unusually influential\n\n\nCheck model diagnositcs\n#many options for which! \nplot(mod1, which=1, cook.levels=cutoff)\n\n\n\n\n\nExample cont.\n\nsummary(mod1)\n\n\nCall:\nlm(formula = mpg ~ vs * cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.3300 -1.4437  0.0875  1.5250  7.1700 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   26.000      3.318   7.836    2e-08 ***\nvs1            0.730      3.480   0.210  0.83541    \ncyl6          -5.433      3.831  -1.418  0.16757    \ncyl8         -10.900      3.434  -3.174  0.00374 ** \nvs1:cyl6      -2.172      4.305  -0.504  0.61801    \nvs1:cyl8          NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.318 on 27 degrees of freedom\nMultiple R-squared:  0.7361,    Adjusted R-squared:  0.697 \nF-statistic: 18.82 on 4 and 27 DF,  p-value: 1.696e-07\n\n\n\nwhile it is nice to see the summary results, you wouldn’t present them in this fashion\n\n\n\nExample cont.\n\nbroom and gt/gtsummary will help\nbroom is a package that helps tidy model results into data.frames\nthis helps with reporting and you can further format the data.frame and present with gt\n\nmoddf <- broom::tidy(mod1) %>% #didn't load broom just called one function \n          mutate(p.value = round(p.value,3)) %>% \n          select(-std.error)\n\ngt::gt(moddf)\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstatistic\n\n\np.value\n\n\n\n\n\n\n\n(Intercept)\n\n\n26.000000\n\n\n7.8364568\n\n\n0.000\n\n\n\n\nvs1\n\n\n0.730000\n\n\n0.2097843\n\n\n0.835\n\n\n\n\ncyl6\n\n\n-5.433333\n\n\n-1.4182193\n\n\n0.168\n\n\n\n\ncyl8\n\n\n-10.900000\n\n\n-3.1738857\n\n\n0.004\n\n\n\n\nvs1:cyl6\n\n\n-2.171667\n\n\n-0.5044923\n\n\n0.618\n\n\n\n\nvs1:cyl8\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\n\n\n\n\ngtsummary\n\ngtsummary makes it easier to report model and descriptive statistics (more on this in the example)\nFor more helpful examples: https://www.danieldsjoberg.com/gtsummary/index.html\n\n\n\ngtsummary\ntbl_regression(mod1)\n\n\n\n\n\n\nCharacteristic\n\n\nBeta\n\n\n95% CI1\n\n\np-value\n\n\n\n\n\n\n\nvs\n\n\n\n\n\n\n\n\n\n\n    0\n\n\n—\n\n\n—\n\n\n\n\n\n\n    1\n\n\n0.73\n\n\n-6.4, 7.9\n\n\n0.8\n\n\n\n\ncyl\n\n\n\n\n\n\n\n\n\n\n    4\n\n\n—\n\n\n—\n\n\n\n\n\n\n    6\n\n\n-5.4\n\n\n-13, 2.4\n\n\n0.2\n\n\n\n\n    8\n\n\n-11\n\n\n-18, -3.9\n\n\n0.004\n\n\n\n\nvs * cyl\n\n\n\n\n\n\n\n\n\n\n    1 * 6\n\n\n-2.2\n\n\n-11, 6.7\n\n\n0.6\n\n\n\n\n    1 * 8\n\n\n\n\n\n\n\n\n\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nCustomizing gtsummary\nlibrary(labelled)\n\nvar_label(mtcars$cyl) <- \"Cylinder\"\nnewmodsum <- lm(mpg ~ vs * cyl, data = mtcars) %>% \ntbl_regression() %>% \n    bold_labels() %>% \n    modify_caption(\"New title for model\")\n\n\nCustomizing gtsummary\nnewmodsum\n\n\n\n\nNew title for model\n\n\n\n\nCharacteristic\n\n\nBeta\n\n\n95% CI1\n\n\np-value\n\n\n\n\n\n\n\nvs\n\n\n\n\n\n\n\n\n\n\n    0\n\n\n—\n\n\n—\n\n\n\n\n\n\n    1\n\n\n0.73\n\n\n-6.4, 7.9\n\n\n0.8\n\n\n\n\nCylinder\n\n\n\n\n\n\n\n\n\n\n    4\n\n\n—\n\n\n—\n\n\n\n\n\n\n    6\n\n\n-5.4\n\n\n-13, 2.4\n\n\n0.2\n\n\n\n\n    8\n\n\n-11\n\n\n-18, -3.9\n\n\n0.004\n\n\n\n\nvs * Cylinder\n\n\n\n\n\n\n\n\n\n\n    1 * 6\n\n\n-2.2\n\n\n-11, 6.7\n\n\n0.6\n\n\n\n\n    1 * 8\n\n\n\n\n\n\n\n\n\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nLogistic models\n\nbinary outcome (0/1)\nR will model the ‘1’ as the event by default make sure your variable is coded correctly\n\nmtcars$vs <- as.numeric(mtcars$vs)\nmtcars$am <- as.character(mtcars$am)\n\nmod2 <- glm(vs ~ am , data = mtcars, family =  \"binomial\")\n\n\nSummarize logistic model\ntbl_regression(mod2, exponentiate = TRUE) %>% \n    bold_labels()\n\n\n\n\n\n\nCharacteristic\n\n\nOR1\n\n\n95% CI1\n\n\np-value\n\n\n\n\n\n\n\nam\n\n\n\n\n\n\n\n\n\n\n    0\n\n\n—\n\n\n—\n\n\n\n\n\n\n    1\n\n\n2.00\n\n\n0.48, 8.76\n\n\n0.3\n\n\n\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nSurvival analysis\n\nOutcome is both time and an event (e.g death, progression)\nHave to specify both in model\n\nFormer MSK employee Emily Zabor put together great materials for survival analysis here: https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html\n\n\n\nSurvival analysis\nlibrary(survival)\n\nlung <- lung %>% \n        mutate(ph.ecog = as.character(ph.ecog),\n               sex = as.character(sex))\n\nmod3 <- coxph(Surv(time, status)~ph.ecog+sex,data = lung)\nmod4 <- survfit(Surv(time, status) ~ sex,data = lung)\n\n\nSurvival analysis\ntbl_regression(mod3, exponentiate = TRUE)\n\n\n\n\n\n\nCharacteristic\n\n\nHR1\n\n\n95% CI1\n\n\np-value\n\n\n\n\n\n\n\nph.ecog\n\n\n\n\n\n\n\n\n\n\n    0\n\n\n—\n\n\n—\n\n\n\n\n\n\n    1\n\n\n1.52\n\n\n1.03, 2.25\n\n\n0.036\n\n\n\n\n    2\n\n\n2.58\n\n\n1.66, 4.01\n\n\n<0.001\n\n\n\n\n    3\n\n\n7.76\n\n\n1.04, 58.0\n\n\n0.046\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n\n\n    1\n\n\n—\n\n\n—\n\n\n\n\n\n\n    2\n\n\n0.58\n\n\n0.42, 0.81\n\n\n0.001\n\n\n\n\n\n\n1 HR = Hazard Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nSurvival analysis\nmod4\nCall: survfit(formula = Surv(time, status) ~ sex, data = lung)\n    n events median 0.95LCL 0.95UCL\nsex=1 138 112 270 212 310 sex=2 90 53 426 348 550\n\n\nSurvival analysis\n\ntest proportional hazards\n\n\ncox.zph(mod3)\n\n        chisq df     p\nph.ecog  5.64  3 0.130\nsex      2.56  1 0.110\nGLOBAL   7.83  4 0.098\n\n\n\n\nTomorrow: Coding Exercise\n\nCase Study: Diabetes Risk Factors\nGithub Repo With Case Study: https://github.com/karissawhiting/qsure-case-study\nCheck out script > 01_clean_data.R\n\n\n\nThank You!"
  }
]